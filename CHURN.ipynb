{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae156c6d",
   "metadata": {},
   "source": [
    "# Customer Churn Data Pipeline\n",
    "## Complete End-to-End Implementation\n",
    "\n",
    "This notebook demonstrates a comprehensive data pipeline for customer churn analysis including:\n",
    "- Data Ingestion with error handling and logging\n",
    "- Raw data storage with efficient folder structure\n",
    "- Data validation and quality checks\n",
    "- Data preparation and EDA\n",
    "- Feature engineering and transformation\n",
    "- Model building and evaluation\n",
    "- Complete pipeline orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ca214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PROJECT SETUP AND CONFIGURATION\n",
    "# Set up project structure and paths\n",
    "\n",
    "# Define project paths\n",
    "PROJECT_ROOT = \"/Users/I528946/Desktop/Use cases/use case 1/AiImageDetection\"\n",
    "DATA_SOURCE = f\"{PROJECT_ROOT}/churn_dataset/cell2cellholdout.csv\"\n",
    "\n",
    "# Create organized folder structure\n",
    "folders = {\n",
    "    'raw_data': f\"{PROJECT_ROOT}/pipeline_data/raw\",\n",
    "    'processed_data': f\"{PROJECT_ROOT}/pipeline_data/processed\", \n",
    "    'transformed_data': f\"{PROJECT_ROOT}/pipeline_data/transformed\",\n",
    "    'models': f\"{PROJECT_ROOT}/pipeline_data/models\",\n",
    "    'reports': f\"{PROJECT_ROOT}/pipeline_data/reports\",\n",
    "    'logs': f\"{PROJECT_ROOT}/pipeline_data/logs\",\n",
    "    'feature_store': f\"{PROJECT_ROOT}/pipeline_data/feature_store\"\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "for folder_name, folder_path in folders.items():\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    print(f\"✓ Created {folder_name}: {folder_path}\")\n",
    "\n",
    "# Setup logging\n",
    "log_filename = f\"{folders['logs']}/pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Pipeline started successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DATA INGESTION WITH ERROR HANDLING AND LOGGING\n",
    "\n",
    "class DataIngestionPipeline:\n",
    "    def __init__(self, source_path, destination_folder):\n",
    "        self.source_path = source_path\n",
    "        self.destination_folder = destination_folder\n",
    "        self.ingestion_metadata = {}\n",
    "    \n",
    "    def validate_source(self):\n",
    "        \"\"\"Validate source file exists and is readable\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(self.source_path):\n",
    "                raise FileNotFoundError(f\"Source file not found: {self.source_path}\")\n",
    "            \n",
    "            # Check file size\n",
    "            file_size = os.path.getsize(self.source_path) / (1024 * 1024)  # MB\n",
    "            logger.info(f\"Source file size: {file_size:.2f} MB\")\n",
    "            \n",
    "            if file_size == 0:\n",
    "                raise ValueError(\"Source file is empty\")\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Source validation failed: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def ingest_data(self):\n",
    "        \"\"\"Ingest data with comprehensive error handling\"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Starting data ingestion from {self.source_path}\")\n",
    "            \n",
    "            # Validate source\n",
    "            if not self.validate_source():\n",
    "                return None\n",
    "            \n",
    "            # Read data with error handling\n",
    "            try:\n",
    "                df = pd.read_csv(self.source_path)\n",
    "                logger.info(f\"Successfully loaded data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                logger.error(\"CSV file is empty\")\n",
    "                return None\n",
    "            except pd.errors.ParserError as e:\n",
    "                logger.error(f\"CSV parsing error: {str(e)}\")\n",
    "                return None\n",
    "            \n",
    "            # Store metadata\n",
    "            self.ingestion_metadata = {\n",
    "                'source_path': self.source_path,\n",
    "                'ingestion_timestamp': datetime.now().isoformat(),\n",
    "                'original_shape': df.shape,\n",
    "                'columns': df.columns.tolist(),\n",
    "                'data_types': df.dtypes.to_dict(),\n",
    "                'file_size_mb': os.path.getsize(self.source_path) / (1024 * 1024)\n",
    "            }\n",
    "            \n",
    "            # Save raw data with timestamp\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            raw_filename = f\"churn_raw_data_{timestamp}.csv\"\n",
    "            raw_filepath = os.path.join(self.destination_folder, raw_filename)\n",
    "            \n",
    "            df.to_csv(raw_filepath, index=False)\n",
    "            logger.info(f\"Raw data saved to: {raw_filepath}\")\n",
    "            \n",
    "            # Save metadata\n",
    "            metadata_filename = f\"ingestion_metadata_{timestamp}.json\"\n",
    "            metadata_filepath = os.path.join(self.destination_folder, metadata_filename)\n",
    "            \n",
    "            with open(metadata_filepath, 'w') as f:\n",
    "                json.dump(self.ingestion_metadata, f, indent=2, default=str)\n",
    "            \n",
    "            logger.info(\"Data ingestion completed successfully\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data ingestion failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Execute data ingestion\n",
    "ingestion_pipeline = DataIngestionPipeline(DATA_SOURCE, folders['raw_data'])\n",
    "df_raw = ingestion_pipeline.ingest_data()\n",
    "\n",
    "if df_raw is not None:\n",
    "    print(f\"✓ Data ingestion successful!\")\n",
    "    print(f\"Shape: {df_raw.shape}\")\n",
    "    print(f\"Columns: {list(df_raw.columns)}\")\n",
    "else:\n",
    "    print(\"✗ Data ingestion failed!\")\n",
    "    raise Exception(\"Cannot proceed without data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DATA VALIDATION AND QUALITY CHECKS\n",
    "\n",
    "class DataValidationPipeline:\n",
    "    def __init__(self, df, output_folder):\n",
    "        self.df = df.copy()\n",
    "        self.output_folder = output_folder\n",
    "        self.validation_report = {}\n",
    "    \n",
    "    def check_missing_data(self):\n",
    "        \"\"\"Check for missing data\"\"\"\n",
    "        missing_data = self.df.isnull().sum()\n",
    "        missing_percentage = (missing_data / len(self.df)) * 100\n",
    "        \n",
    "        missing_report = pd.DataFrame({\n",
    "            'Column': missing_data.index,\n",
    "            'Missing_Count': missing_data.values,\n",
    "            'Missing_Percentage': missing_percentage.values\n",
    "        }).sort_values('Missing_Percentage', ascending=False)\n",
    "        \n",
    "        self.validation_report['missing_data'] = missing_report.to_dict('records')\n",
    "        logger.info(f\"Missing data check completed. Columns with missing data: {sum(missing_data > 0)}\")\n",
    "        return missing_report\n",
    "    \n",
    "    def check_data_types(self):\n",
    "        \"\"\"Validate data types and identify inconsistencies\"\"\"\n",
    "        type_info = pd.DataFrame({\n",
    "            'Column': self.df.columns,\n",
    "            'Data_Type': self.df.dtypes.values,\n",
    "            'Non_Null_Count': self.df.count().values,\n",
    "            'Unique_Values': [self.df[col].nunique() for col in self.df.columns]\n",
    "        })\n",
    "        \n",
    "        # Check for potential type issues\n",
    "        type_issues = []\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype == 'object':\n",
    "                # Check if numeric values stored as strings\n",
    "                try:\n",
    "                    pd.to_numeric(self.df[col], errors='raise')\n",
    "                    type_issues.append(f\"{col}: Numeric values stored as strings\")\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        self.validation_report['data_types'] = type_info.to_dict('records')\n",
    "        self.validation_report['type_issues'] = type_issues\n",
    "        logger.info(f\"Data type validation completed. Potential issues found: {len(type_issues)}\")\n",
    "        return type_info, type_issues\n",
    "    \n",
    "    def check_duplicates(self):\n",
    "        \"\"\"Check for duplicate records\"\"\"\n",
    "        total_duplicates = self.df.duplicated().sum()\n",
    "        duplicate_percentage = (total_duplicates / len(self.df)) * 100\n",
    "        \n",
    "        # Check duplicates by key columns (if identifiable)\n",
    "        duplicate_info = {\n",
    "            'total_duplicates': int(total_duplicates),\n",
    "            'duplicate_percentage': float(duplicate_percentage),\n",
    "            'total_rows': len(self.df)\n",
    "        }\n",
    "        \n",
    "        self.validation_report['duplicates'] = duplicate_info\n",
    "        logger.info(f\"Duplicate check completed. Found {total_duplicates} duplicates ({duplicate_percentage:.2f}%)\")\n",
    "        return duplicate_info\n",
    "    \n",
    "    def check_data_ranges(self):\n",
    "        \"\"\"Check data ranges and identify outliers\"\"\"\n",
    "        numeric_columns = self.df.select_dtypes(include=[np.number]).columns\n",
    "        range_analysis = {}\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            col_stats = {\n",
    "                'column': col,\n",
    "                'min': float(self.df[col].min()),\n",
    "                'max': float(self.df[col].max()),\n",
    "                'mean': float(self.df[col].mean()),\n",
    "                'std': float(self.df[col].std()),\n",
    "                'q25': float(self.df[col].quantile(0.25)),\n",
    "                'q75': float(self.df[col].quantile(0.75))\n",
    "            }\n",
    "            \n",
    "            # Identify potential outliers using IQR method\n",
    "            iqr = col_stats['q75'] - col_stats['q25']\n",
    "            lower_bound = col_stats['q25'] - 1.5 * iqr\n",
    "            upper_bound = col_stats['q75'] + 1.5 * iqr\n",
    "            \n",
    "            outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)][col]\n",
    "            col_stats['outlier_count'] = len(outliers)\n",
    "            col_stats['outlier_percentage'] = (len(outliers) / len(self.df)) * 100\n",
    "            \n",
    "            range_analysis[col] = col_stats\n",
    "        \n",
    "        self.validation_report['range_analysis'] = range_analysis\n",
    "        logger.info(f\"Range analysis completed for {len(numeric_columns)} numeric columns\")\n",
    "        return range_analysis\n",
    "    \n",
    "    def generate_quality_report(self):\n",
    "        \"\"\"Generate comprehensive data quality report\"\"\"\n",
    "        logger.info(\"Generating comprehensive data quality report...\")\n",
    "        \n",
    "        # Run all validation checks\n",
    "        missing_report = self.check_missing_data()\n",
    "        type_info, type_issues = self.check_data_types()\n",
    "        duplicate_info = self.check_duplicates()\n",
    "        range_analysis = self.check_data_ranges()\n",
    "        \n",
    "        # Create summary\n",
    "        summary = {\n",
    "            'dataset_info': {\n",
    "                'total_rows': len(self.df),\n",
    "                'total_columns': len(self.df.columns),\n",
    "                'validation_timestamp': datetime.now().isoformat()\n",
    "            },\n",
    "            'quality_score': self.calculate_quality_score(),\n",
    "            'recommendations': self.generate_recommendations()\n",
    "        }\n",
    "        \n",
    "        self.validation_report['summary'] = summary\n",
    "        \n",
    "        # Save report\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_filename = f\"data_quality_report_{timestamp}.json\"\n",
    "        report_filepath = os.path.join(self.output_folder, report_filename)\n",
    "        \n",
    "        with open(report_filepath, 'w') as f:\n",
    "            json.dump(self.validation_report, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Data quality report saved to: {report_filepath}\")\n",
    "        return self.validation_report\n",
    "    \n",
    "    def calculate_quality_score(self):\n",
    "        \"\"\"Calculate overall data quality score (0-100)\"\"\"\n",
    "        score = 100\n",
    "        \n",
    "        # Deduct for missing data\n",
    "        missing_penalty = sum([col['Missing_Percentage'] for col in self.validation_report['missing_data']]) / len(self.validation_report['missing_data'])\n",
    "        score -= missing_penalty * 0.3\n",
    "        \n",
    "        # Deduct for duplicates\n",
    "        score -= self.validation_report['duplicates']['duplicate_percentage'] * 0.5\n",
    "        \n",
    "        # Deduct for type issues\n",
    "        score -= len(self.validation_report['type_issues']) * 5\n",
    "        \n",
    "        return max(0, round(score, 2))\n",
    "    \n",
    "    def generate_recommendations(self):\n",
    "        \"\"\"Generate data quality improvement recommendations\"\"\"\n",
    "        recommendations = []\n",
    "        \n",
    "        # Missing data recommendations\n",
    "        high_missing_cols = [col for col in self.validation_report['missing_data'] if col['Missing_Percentage'] > 20]\n",
    "        if high_missing_cols:\n",
    "            recommendations.append(f\"Consider removing columns with >20% missing data: {[col['Column'] for col in high_missing_cols]}\")\n",
    "        \n",
    "        # Duplicate recommendations\n",
    "        if self.validation_report['duplicates']['total_duplicates'] > 0:\n",
    "            recommendations.append(\"Remove duplicate records to improve data quality\")\n",
    "        \n",
    "        # Type issues recommendations\n",
    "        if self.validation_report['type_issues']:\n",
    "            recommendations.append(\"Fix data type inconsistencies before processing\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Execute data validation\n",
    "validation_pipeline = DataValidationPipeline(df_raw, folders['reports'])\n",
    "quality_report = validation_pipeline.generate_quality_report()\n",
    "\n",
    "print(f\"✓ Data Quality Score: {quality_report['summary']['quality_score']}/100\")\n",
    "print(f\"✓ Total Rows: {quality_report['summary']['dataset_info']['total_rows']}\")\n",
    "print(f\"✓ Total Columns: {quality_report['summary']['dataset_info']['total_columns']}\")\n",
    "print(f\"✓ Missing Data Issues: {len([col for col in quality_report['missing_data'] if col['Missing_Percentage'] > 0])}\")\n",
    "print(f\"✓ Duplicate Records: {quality_report['duplicates']['total_duplicates']}\")\n",
    "print(f\"✓ Type Issues: {len(quality_report['type_issues'])}\")\n",
    "\n",
    "if quality_report['summary']['recommendations']:\n",
    "    print(\"\\n⚠️  Recommendations:\")\n",
    "    for rec in quality_report['summary']['recommendations']:\n",
    "        print(f\"  - {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DATA PREPARATION AND EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "class DataPreparationPipeline:\n",
    "    def __init__(self, df, output_folder):\n",
    "        self.df = df.copy()\n",
    "        self.output_folder = output_folder\n",
    "        self.preparation_log = []\n",
    "    \n",
    "    def handle_missing_values(self, strategy='auto'):\n",
    "        \"\"\"Handle missing values with different strategies\"\"\"\n",
    "        logger.info(\"Handling missing values...\")\n",
    "        \n",
    "        missing_before = self.df.isnull().sum().sum()\n",
    "        \n",
    "        for column in self.df.columns:\n",
    "            missing_count = self.df[column].isnull().sum()\n",
    "            \n",
    "            if missing_count > 0:\n",
    "                missing_pct = (missing_count / len(self.df)) * 100\n",
    "                \n",
    "                if missing_pct > 50:\n",
    "                    # Drop columns with >50% missing\n",
    "                    self.df = self.df.drop(column, axis=1)\n",
    "                    self.preparation_log.append(f\"Dropped column {column} (missing: {missing_pct:.1f}%)\")\n",
    "                    logger.info(f\"Dropped column {column} due to high missing percentage\")\n",
    "                \n",
    "                elif self.df[column].dtype in ['int64', 'float64']:\n",
    "                    # Fill numeric with median\n",
    "                    median_val = self.df[column].median()\n",
    "                    self.df[column] = self.df[column].fillna(median_val)\n",
    "                    self.preparation_log.append(f\"Filled {column} missing values with median: {median_val}\")\n",
    "                \n",
    "                else:\n",
    "                    # Fill categorical with mode\n",
    "                    mode_val = self.df[column].mode()[0] if not self.df[column].mode().empty else 'Unknown'\n",
    "                    self.df[column] = self.df[column].fillna(mode_val)\n",
    "                    self.preparation_log.append(f\"Filled {column} missing values with mode: {mode_val}\")\n",
    "        \n",
    "        missing_after = self.df.isnull().sum().sum()\n",
    "        logger.info(f\"Missing values reduced from {missing_before} to {missing_after}\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Remove duplicate records\"\"\"\n",
    "        before_count = len(self.df)\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        after_count = len(self.df)\n",
    "        \n",
    "        removed = before_count - after_count\n",
    "        if removed > 0:\n",
    "            self.preparation_log.append(f\"Removed {removed} duplicate records\")\n",
    "            logger.info(f\"Removed {removed} duplicate records\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def detect_and_handle_outliers(self, method='iqr', threshold=1.5):\n",
    "        \"\"\"Detect and handle outliers in numeric columns\"\"\"\n",
    "        numeric_columns = self.df.select_dtypes(include=[np.number]).columns\n",
    "        outlier_summary = {}\n",
    "        \n",
    "        for column in numeric_columns:\n",
    "            if method == 'iqr':\n",
    "                Q1 = self.df[column].quantile(0.25)\n",
    "                Q3 = self.df[column].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                lower_bound = Q1 - threshold * IQR\n",
    "                upper_bound = Q3 + threshold * IQR\n",
    "                \n",
    "                outliers = self.df[(self.df[column] < lower_bound) | (self.df[column] > upper_bound)]\n",
    "                outlier_count = len(outliers)\n",
    "                \n",
    "                if outlier_count > 0:\n",
    "                    outlier_percentage = (outlier_count / len(self.df)) * 100\n",
    "                    outlier_summary[column] = {\n",
    "                        'count': outlier_count,\n",
    "                        'percentage': outlier_percentage,\n",
    "                        'lower_bound': lower_bound,\n",
    "                        'upper_bound': upper_bound\n",
    "                    }\n",
    "                    \n",
    "                    # Cap outliers instead of removing (less aggressive)\n",
    "                    self.df.loc[self.df[column] < lower_bound, column] = lower_bound\n",
    "                    self.df.loc[self.df[column] > upper_bound, column] = upper_bound\n",
    "                    \n",
    "                    self.preparation_log.append(f\"Capped {outlier_count} outliers in {column}\")\n",
    "                    logger.info(f\"Capped outliers in {column}: {outlier_count} values\")\n",
    "        \n",
    "        return self.df, outlier_summary\n",
    "    \n",
    "    def perform_eda(self):\n",
    "        \"\"\"Perform comprehensive exploratory data analysis\"\"\"\n",
    "        logger.info(\"Performing exploratory data analysis...\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Exploratory Data Analysis - Churn Dataset', fontsize=16)\n",
    "        \n",
    "        # 1. Dataset shape and info\n",
    "        axes[0, 0].text(0.1, 0.8, f\"Dataset Shape: {self.df.shape}\", fontsize=14, transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].text(0.1, 0.6, f\"Memory Usage: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\", fontsize=12, transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].text(0.1, 0.4, f\"Numeric Columns: {len(self.df.select_dtypes(include=[np.number]).columns)}\", fontsize=12, transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].text(0.1, 0.2, f\"Categorical Columns: {len(self.df.select_dtypes(include=['object']).columns)}\", fontsize=12, transform=axes[0, 0].transAxes)\n",
    "        axes[0, 0].set_title('Dataset Overview')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        # 2. Missing data heatmap\n",
    "        missing_data = self.df.isnull().sum()\n",
    "        if missing_data.sum() > 0:\n",
    "            missing_df = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "            axes[0, 1].bar(range(len(missing_df)), missing_df.values)\n",
    "            axes[0, 1].set_xticks(range(len(missing_df)))\n",
    "            axes[0, 1].set_xticklabels(missing_df.index, rotation=45)\n",
    "            axes[0, 1].set_title('Missing Values by Column')\n",
    "            axes[0, 1].set_ylabel('Count')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'No Missing Values', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "            axes[0, 1].set_title('Missing Values by Column')\n",
    "        \n",
    "        # 3. Numeric data distribution\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            # Select first few numeric columns for distribution plot\n",
    "            cols_to_plot = numeric_cols[:4]  # Plot first 4 numeric columns\n",
    "            for i, col in enumerate(cols_to_plot):\n",
    "                if i < 2:  # Only 2 subplots for distributions\n",
    "                    row, col_idx = (1, i)\n",
    "                    self.df[col].hist(bins=30, ax=axes[row, col_idx], alpha=0.7)\n",
    "                    axes[row, col_idx].set_title(f'Distribution of {col}')\n",
    "                    axes[row, col_idx].set_xlabel(col)\n",
    "                    axes[row, col_idx].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save EDA plot\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        eda_filename = f\"eda_analysis_{timestamp}.png\"\n",
    "        eda_filepath = os.path.join(self.output_folder, eda_filename)\n",
    "        plt.savefig(eda_filepath, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Generate statistical summary\n",
    "        summary_stats = {\n",
    "            'numeric_summary': self.df.describe().to_dict(),\n",
    "            'categorical_summary': {},\n",
    "            'correlation_analysis': {}\n",
    "        }\n",
    "        \n",
    "        # Categorical summary\n",
    "        categorical_cols = self.df.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            summary_stats['categorical_summary'][col] = {\n",
    "                'unique_values': int(self.df[col].nunique()),\n",
    "                'top_values': self.df[col].value_counts().head().to_dict(),\n",
    "                'most_frequent': str(self.df[col].mode()[0]) if not self.df[col].mode().empty else 'N/A'\n",
    "            }\n",
    "        \n",
    "        # Correlation analysis for numeric columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            correlation_matrix = self.df[numeric_cols].corr()\n",
    "            summary_stats['correlation_analysis'] = correlation_matrix.to_dict()\n",
    "            \n",
    "            # Plot correlation heatmap\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                       square=True, fmt='.2f')\n",
    "            plt.title('Feature Correlation Heatmap')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            corr_filename = f\"correlation_heatmap_{timestamp}.png\"\n",
    "            corr_filepath = os.path.join(self.output_folder, corr_filename)\n",
    "            plt.savefig(corr_filepath, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        # Save statistical summary\n",
    "        stats_filename = f\"statistical_summary_{timestamp}.json\"\n",
    "        stats_filepath = os.path.join(self.output_folder, stats_filename)\n",
    "        \n",
    "        with open(stats_filepath, 'w') as f:\n",
    "            json.dump(summary_stats, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"EDA completed. Reports saved to {self.output_folder}\")\n",
    "        return summary_stats\n",
    "    \n",
    "    def prepare_clean_dataset(self):\n",
    "        \"\"\"Execute complete data preparation pipeline\"\"\"\n",
    "        logger.info(\"Starting data preparation pipeline...\")\n",
    "        \n",
    "        # Apply all preparation steps\n",
    "        self.handle_missing_values()\n",
    "        self.remove_duplicates()\n",
    "        outlier_info = self.detect_and_handle_outliers()\n",
    "        \n",
    "        # Perform EDA\n",
    "        eda_results = self.perform_eda()\n",
    "        \n",
    "        # Save cleaned dataset\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        clean_filename = f\"cleaned_churn_data_{timestamp}.csv\"\n",
    "        clean_filepath = os.path.join(self.output_folder, clean_filename)\n",
    "        \n",
    "        self.df.to_csv(clean_filepath, index=False)\n",
    "        logger.info(f\"Cleaned dataset saved to: {clean_filepath}\")\n",
    "        \n",
    "        # Save preparation log\n",
    "        log_filename = f\"preparation_log_{timestamp}.json\"\n",
    "        log_filepath = os.path.join(self.output_folder, log_filename)\n",
    "        \n",
    "        preparation_summary = {\n",
    "            'preparation_steps': self.preparation_log,\n",
    "            'final_shape': self.df.shape,\n",
    "            'outlier_summary': outlier_info[1] if isinstance(outlier_info, tuple) else {},\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(log_filepath, 'w') as f:\n",
    "            json.dump(preparation_summary, f, indent=2, default=str)\n",
    "        \n",
    "        return self.df\n",
    "\n",
    "# Execute data preparation\n",
    "preparation_pipeline = DataPreparationPipeline(df_raw, folders['processed_data'])\n",
    "df_clean = preparation_pipeline.prepare_clean_dataset()\n",
    "\n",
    "print(f\"✓ Data preparation completed!\")\n",
    "print(f\"✓ Original shape: {df_raw.shape}\")\n",
    "print(f\"✓ Cleaned shape: {df_clean.shape}\")\n",
    "print(f\"✓ Preparation steps applied: {len(preparation_pipeline.preparation_log)}\")\n",
    "if preparation_pipeline.preparation_log:\n",
    "    print(\"✓ Key preparation steps:\")\n",
    "    for step in preparation_pipeline.preparation_log[:5]:  # Show first 5 steps\n",
    "        print(f\"  - {step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. FEATURE ENGINEERING AND TRANSFORMATION\n",
    "\n",
    "class FeatureEngineeringPipeline:\n",
    "    def __init__(self, df, output_folder):\n",
    "        self.df = df.copy()\n",
    "        self.output_folder = output_folder\n",
    "        self.feature_metadata = {}\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "        \n",
    "    def identify_target_variable(self):\n",
    "        \"\"\"Identify the target variable for churn prediction\"\"\"\n",
    "        # Look for churn-related columns\n",
    "        churn_candidates = [col for col in self.df.columns if 'churn' in col.lower()]\n",
    "        \n",
    "        if churn_candidates:\n",
    "            target_col = churn_candidates[0]\n",
    "            logger.info(f\"Identified target variable: {target_col}\")\n",
    "        else:\n",
    "            # If no explicit churn column, look for binary variables\n",
    "            binary_cols = []\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].nunique() == 2:\n",
    "                    binary_cols.append(col)\n",
    "            \n",
    "            if binary_cols:\n",
    "                target_col = binary_cols[0]  # Take first binary column as target\n",
    "                logger.info(f\"Using binary column as target: {target_col}\")\n",
    "            else:\n",
    "                # Create a synthetic target for demonstration\n",
    "                target_col = 'churn_flag'\n",
    "                # Create churn based on some business logic (example)\n",
    "                numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "                if len(numeric_cols) > 0:\n",
    "                    # Use top 30% of first numeric column as churn indicator\n",
    "                    threshold = self.df[numeric_cols[0]].quantile(0.7)\n",
    "                    self.df[target_col] = (self.df[numeric_cols[0]] > threshold).astype(int)\n",
    "                    logger.info(f\"Created synthetic target variable: {target_col}\")\n",
    "                else:\n",
    "                    raise ValueError(\"Cannot identify or create target variable\")\n",
    "        \n",
    "        return target_col\n",
    "    \n",
    "    def create_aggregated_features(self, target_col):\n",
    "        \"\"\"Create aggregated features for customer analysis\"\"\"\n",
    "        logger.info(\"Creating aggregated features...\")\n",
    "        \n",
    "        # Get numeric columns (excluding target)\n",
    "        numeric_cols = [col for col in self.df.select_dtypes(include=[np.number]).columns if col != target_col]\n",
    "        \n",
    "        if len(numeric_cols) >= 2:\n",
    "            # Total spend/usage features\n",
    "            spending_cols = [col for col in numeric_cols if any(keyword in col.lower() for keyword in ['charge', 'fee', 'revenue', 'bill', 'amount'])]\n",
    "            usage_cols = [col for col in numeric_cols if any(keyword in col.lower() for keyword in ['minutes', 'calls', 'usage', 'data'])]\n",
    "            \n",
    "            if spending_cols:\n",
    "                self.df['total_spending'] = self.df[spending_cols].sum(axis=1)\n",
    "                self.feature_metadata['total_spending'] = {\n",
    "                    'description': 'Total spending across all services',\n",
    "                    'source_columns': spending_cols,\n",
    "                    'creation_date': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            if usage_cols:\n",
    "                self.df['total_usage'] = self.df[usage_cols].sum(axis=1)\n",
    "                self.feature_metadata['total_usage'] = {\n",
    "                    'description': 'Total usage across all services',\n",
    "                    'source_columns': usage_cols,\n",
    "                    'creation_date': datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            # Average features\n",
    "            self.df['avg_numeric'] = self.df[numeric_cols].mean(axis=1)\n",
    "            self.feature_metadata['avg_numeric'] = {\n",
    "                'description': 'Average of all numeric features',\n",
    "                'source_columns': numeric_cols,\n",
    "                'creation_date': datetime.now().isoformat()\n",
    "            }\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def create_derived_features(self, target_col):\n",
    "        \"\"\"Create derived features based on business logic\"\"\"\n",
    "        logger.info(\"Creating derived features...\")\n",
    "        \n",
    "        # Get numeric columns\n",
    "        numeric_cols = [col for col in self.df.select_dtypes(include=[np.number]).columns if col != target_col]\n",
    "        \n",
    "        if len(numeric_cols) >= 1:\n",
    "            # High value customer indicator\n",
    "            first_numeric = numeric_cols[0]\n",
    "            threshold = self.df[first_numeric].quantile(0.8)\n",
    "            self.df['high_value_customer'] = (self.df[first_numeric] > threshold).astype(int)\n",
    "            \n",
    "            self.feature_metadata['high_value_customer'] = {\n",
    "                'description': f'Indicator for customers in top 20% of {first_numeric}',\n",
    "                'source_columns': [first_numeric],\n",
    "                'threshold': threshold,\n",
    "                'creation_date': datetime.now().isoformat()\n",
    "            }\n",
    "        \n",
    "        # Customer tenure/activity features (if date columns exist)\n",
    "        date_cols = self.df.select_dtypes(include=['datetime64']).columns\n",
    "        if len(date_cols) > 0:\n",
    "            for date_col in date_cols:\n",
    "                # Days since last activity\n",
    "                self.df[f'{date_col}_days_ago'] = (datetime.now() - self.df[date_col]).dt.days\n",
    "                \n",
    "                self.feature_metadata[f'{date_col}_days_ago'] = {\n",
    "                    'description': f'Days since {date_col}',\n",
    "                    'source_columns': [date_col],\n",
    "                    'creation_date': datetime.now().isoformat()\n",
    "                }\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def encode_categorical_variables(self, target_col):\n",
    "        \"\"\"Encode categorical variables\"\"\"\n",
    "        logger.info(\"Encoding categorical variables...\")\n",
    "        \n",
    "        categorical_cols = [col for col in self.df.select_dtypes(include=['object']).columns if col != target_col]\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            unique_values = self.df[col].nunique()\n",
    "            \n",
    "            if unique_values <= 10:  # Use one-hot encoding for low cardinality\n",
    "                # One-hot encoding\n",
    "                dummies = pd.get_dummies(self.df[col], prefix=col, drop_first=True)\n",
    "                self.df = pd.concat([self.df, dummies], axis=1)\n",
    "                self.df = self.df.drop(col, axis=1)\n",
    "                \n",
    "                self.feature_metadata[f'{col}_encoded'] = {\n",
    "                    'description': f'One-hot encoded {col}',\n",
    "                    'encoding_type': 'one_hot',\n",
    "                    'original_categories': self.df[col].unique().tolist() if col in self.df.columns else [],\n",
    "                    'creation_date': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "            else:  # Use label encoding for high cardinality\n",
    "                le = LabelEncoder()\n",
    "                self.df[f'{col}_encoded'] = le.fit_transform(self.df[col])\n",
    "                self.df = self.df.drop(col, axis=1)\n",
    "                \n",
    "                self.encoders[col] = le\n",
    "                self.feature_metadata[f'{col}_encoded'] = {\n",
    "                    'description': f'Label encoded {col}',\n",
    "                    'encoding_type': 'label',\n",
    "                    'categories': le.classes_.tolist(),\n",
    "                    'creation_date': datetime.now().isoformat()\n",
    "                }\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def scale_features(self, target_col):\n",
    "        \"\"\"Scale numerical features\"\"\"\n",
    "        logger.info(\"Scaling numerical features...\")\n",
    "        \n",
    "        # Get numeric columns (excluding target and derived binary features)\n",
    "        numeric_cols = []\n",
    "        for col in self.df.select_dtypes(include=[np.number]).columns:\n",
    "            if col != target_col and not col.endswith('_encoded') and self.df[col].nunique() > 2:\n",
    "                numeric_cols.append(col)\n",
    "        \n",
    "        if numeric_cols:\n",
    "            scaler = StandardScaler()\n",
    "            self.df[numeric_cols] = scaler.fit_transform(self.df[numeric_cols])\n",
    "            self.scalers['standard_scaler'] = scaler\n",
    "            \n",
    "            self.feature_metadata['scaling'] = {\n",
    "                'description': 'StandardScaler applied to numeric features',\n",
    "                'scaled_columns': numeric_cols,\n",
    "                'scaler_type': 'StandardScaler',\n",
    "                'creation_date': datetime.now().isoformat()\n",
    "            }\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def create_feature_store(self):\n",
    "        \"\"\"Create and populate feature store\"\"\"\n",
    "        logger.info(\"Creating feature store...\")\n",
    "        \n",
    "        # Save feature metadata\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        metadata_filename = f\"feature_metadata_{timestamp}.json\"\n",
    "        metadata_filepath = os.path.join(folders['feature_store'], metadata_filename)\n",
    "        \n",
    "        with open(metadata_filepath, 'w') as f:\n",
    "            json.dump(self.feature_metadata, f, indent=2, default=str)\n",
    "        \n",
    "        # Save encoders and scalers\n",
    "        encoders_filename = f\"encoders_{timestamp}.joblib\"\n",
    "        encoders_filepath = os.path.join(folders['feature_store'], encoders_filename)\n",
    "        joblib.dump(self.encoders, encoders_filepath)\n",
    "        \n",
    "        scalers_filename = f\"scalers_{timestamp}.joblib\"\n",
    "        scalers_filepath = os.path.join(folders['feature_store'], scalers_filename)\n",
    "        joblib.dump(self.scalers, scalers_filepath)\n",
    "        \n",
    "        # Save transformed dataset\n",
    "        transformed_filename = f\"transformed_features_{timestamp}.csv\"\n",
    "        transformed_filepath = os.path.join(folders['transformed_data'], transformed_filename)\n",
    "        self.df.to_csv(transformed_filepath, index=False)\n",
    "        \n",
    "        logger.info(f\"Feature store created with {len(self.feature_metadata)} features\")\n",
    "        return {\n",
    "            'metadata_path': metadata_filepath,\n",
    "            'encoders_path': encoders_filepath,\n",
    "            'scalers_path': scalers_filepath,\n",
    "            'transformed_data_path': transformed_filepath\n",
    "        }\n",
    "    \n",
    "    def execute_feature_engineering(self):\n",
    "        \"\"\"Execute complete feature engineering pipeline\"\"\"\n",
    "        logger.info(\"Starting feature engineering pipeline...\")\n",
    "        \n",
    "        # Identify target variable\n",
    "        target_col = self.identify_target_variable()\n",
    "        \n",
    "        # Create features\n",
    "        self.create_aggregated_features(target_col)\n",
    "        self.create_derived_features(target_col)\n",
    "        self.encode_categorical_variables(target_col)\n",
    "        self.scale_features(target_col)\n",
    "        \n",
    "        # Create feature store\n",
    "        feature_store_paths = self.create_feature_store()\n",
    "        \n",
    "        logger.info(\"Feature engineering completed successfully\")\n",
    "        return self.df, target_col, feature_store_paths\n",
    "\n",
    "# Execute feature engineering\n",
    "feature_pipeline = FeatureEngineeringPipeline(df_clean, folders['transformed_data'])\n",
    "df_transformed, target_column, feature_store_info = feature_pipeline.execute_feature_engineering()\n",
    "\n",
    "print(f\"✓ Feature engineering completed!\")\n",
    "print(f\"✓ Target variable: {target_column}\")\n",
    "print(f\"✓ Original features: {df_clean.shape[1]}\")\n",
    "print(f\"✓ Transformed features: {df_transformed.shape[1]}\")\n",
    "print(f\"✓ Feature metadata entries: {len(feature_pipeline.feature_metadata)}\")\n",
    "print(f\"✓ Encoders created: {len(feature_pipeline.encoders)}\")\n",
    "print(f\"✓ Scalers created: {len(feature_pipeline.scalers)}\")\n",
    "\n",
    "# Display sample of transformed data\n",
    "print(\"\\n✓ Sample of transformed data:\")\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4db8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. MODEL BUILDING AND EVALUATION\n",
    "\n",
    "class ModelBuildingPipeline:\n",
    "    def __init__(self, df, target_column, output_folder):\n",
    "        self.df = df.copy()\n",
    "        self.target_column = target_column\n",
    "        self.output_folder = output_folder\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def prepare_model_data(self):\n",
    "        \"\"\"Prepare data for modeling\"\"\"\n",
    "        logger.info(\"Preparing data for modeling...\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = self.df.drop(columns=[self.target_column])\n",
    "        y = self.df[self.target_column]\n",
    "        \n",
    "        # Handle any remaining missing values\n",
    "        X = X.fillna(X.mean() if X.select_dtypes(include=[np.number]).shape[1] > 0 else 0)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y if len(y.unique()) > 1 else None\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "        logger.info(f\"Target distribution - Train: {y_train.value_counts().to_dict()}\")\n",
    "        logger.info(f\"Target distribution - Test: {y_test.value_counts().to_dict()}\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def train_models(self, X_train, y_train):\n",
    "        \"\"\"Train multiple machine learning models\"\"\"\n",
    "        logger.info(\"Training machine learning models...\")\n",
    "        \n",
    "        # Define models to train\n",
    "        models_config = {\n",
    "            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'random_forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "        }\n",
    "        \n",
    "        # Train each model\n",
    "        for name, model in models_config.items():\n",
    "            try:\n",
    "                logger.info(f\"Training {name}...\")\n",
    "                model.fit(X_train, y_train)\n",
    "                self.models[name] = model\n",
    "                logger.info(f\"Successfully trained {name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to train {name}: {str(e)}\")\n",
    "        \n",
    "        return self.models\n",
    "    \n",
    "    def evaluate_models(self, X_test, y_test):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        logger.info(\"Evaluating models...\")\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                # Make predictions\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "                \n",
    "                # Calculate metrics\n",
    "                accuracy = (y_pred == y_test).mean()\n",
    "                \n",
    "                # Classification report\n",
    "                class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "                \n",
    "                # ROC AUC (if binary classification)\n",
    "                roc_auc = None\n",
    "                if y_pred_proba is not None and len(np.unique(y_test)) == 2:\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "                \n",
    "                # Store results\n",
    "                self.results[name] = {\n",
    "                    'accuracy': accuracy,\n",
    "                    'classification_report': class_report,\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'predictions': y_pred.tolist(),\n",
    "                    'prediction_probabilities': y_pred_proba.tolist() if y_pred_proba is not None else None\n",
    "                }\n",
    "                \n",
    "                logger.info(f\"{name} - Accuracy: {accuracy:.4f}, ROC AUC: {roc_auc:.4f if roc_auc else 'N/A'}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to evaluate {name}: {str(e)}\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def generate_model_report(self, X_test, y_test):\n",
    "        \"\"\"Generate comprehensive model evaluation report\"\"\"\n",
    "        logger.info(\"Generating model evaluation report...\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        n_models = len(self.models)\n",
    "        if n_models == 0:\n",
    "            logger.warning(\"No trained models to evaluate\")\n",
    "            return None\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Model Evaluation Report', fontsize=16)\n",
    "        \n",
    "        # 1. Model accuracy comparison\n",
    "        model_names = list(self.results.keys())\n",
    "        accuracies = [self.results[name]['accuracy'] for name in model_names]\n",
    "        \n",
    "        axes[0, 0].bar(model_names, accuracies, alpha=0.7)\n",
    "        axes[0, 0].set_title('Model Accuracy Comparison')\n",
    "        axes[0, 0].set_ylabel('Accuracy')\n",
    "        axes[0, 0].set_ylim(0, 1)\n",
    "        for i, acc in enumerate(accuracies):\n",
    "            axes[0, 0].text(i, acc + 0.01, f'{acc:.3f}', ha='center')\n",
    "        \n",
    "        # 2. ROC Curves (if applicable)\n",
    "        axes[0, 1].set_title('ROC Curves')\n",
    "        for name in model_names:\n",
    "            if self.results[name]['roc_auc'] is not None:\n",
    "                y_pred_proba = np.array(self.results[name]['prediction_probabilities'])\n",
    "                fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "                auc_score = self.results[name]['roc_auc']\n",
    "                axes[0, 1].plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})')\n",
    "        \n",
    "        axes[0, 1].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        axes[0, 1].set_xlabel('False Positive Rate')\n",
    "        axes[0, 1].set_ylabel('True Positive Rate')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Confusion Matrix for best model\n",
    "        best_model_name = max(model_names, key=lambda x: self.results[x]['accuracy'])\n",
    "        best_predictions = np.array(self.results[best_model_name]['predictions'])\n",
    "        \n",
    "        cm = confusion_matrix(y_test, best_predictions)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', ax=axes[1, 0], cmap='Blues')\n",
    "        axes[1, 0].set_title(f'Confusion Matrix - {best_model_name}')\n",
    "        axes[1, 0].set_xlabel('Predicted')\n",
    "        axes[1, 0].set_ylabel('Actual')\n",
    "        \n",
    "        # 4. Feature importance (if available)\n",
    "        if hasattr(self.models[best_model_name], 'feature_importances_'):\n",
    "            feature_names = self.df.drop(columns=[self.target_column]).columns\n",
    "            importances = self.models[best_model_name].feature_importances_\n",
    "            \n",
    "            # Get top 10 features\n",
    "            top_indices = np.argsort(importances)[-10:]\n",
    "            top_features = [feature_names[i] for i in top_indices]\n",
    "            top_importances = importances[top_indices]\n",
    "            \n",
    "            axes[1, 1].barh(range(len(top_features)), top_importances)\n",
    "            axes[1, 1].set_yticks(range(len(top_features)))\n",
    "            axes[1, 1].set_yticklabels(top_features)\n",
    "            axes[1, 1].set_title(f'Top 10 Feature Importances - {best_model_name}')\n",
    "            axes[1, 1].set_xlabel('Importance')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Feature importance\\nnot available', \n",
    "                           ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].set_title('Feature Importance')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_filename = f\"model_evaluation_report_{timestamp}.png\"\n",
    "        report_filepath = os.path.join(self.output_folder, report_filename)\n",
    "        plt.savefig(report_filepath, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return report_filepath\n",
    "    \n",
    "    def save_best_model(self):\n",
    "        \"\"\"Save the best performing model\"\"\"\n",
    "        if not self.models:\n",
    "            logger.warning(\"No models to save\")\n",
    "            return None\n",
    "        \n",
    "        # Find best model based on accuracy\n",
    "        best_model_name = max(self.results.keys(), key=lambda x: self.results[x]['accuracy'])\n",
    "        best_model = self.models[best_model_name]\n",
    "        best_accuracy = self.results[best_model_name]['accuracy']\n",
    "        \n",
    "        # Save model\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        model_filename = f\"best_churn_model_{timestamp}.joblib\"\n",
    "        model_filepath = os.path.join(self.output_folder, model_filename)\n",
    "        \n",
    "        joblib.dump(best_model, model_filepath)\n",
    "        \n",
    "        # Save model metadata\n",
    "        model_metadata = {\n",
    "            'model_name': best_model_name,\n",
    "            'model_type': type(best_model).__name__,\n",
    "            'accuracy': best_accuracy,\n",
    "            'roc_auc': self.results[best_model_name]['roc_auc'],\n",
    "            'training_timestamp': datetime.now().isoformat(),\n",
    "            'features_used': self.df.drop(columns=[self.target_column]).columns.tolist(),\n",
    "            'target_column': self.target_column,\n",
    "            'model_path': model_filepath\n",
    "        }\n",
    "        \n",
    "        metadata_filename = f\"model_metadata_{timestamp}.json\"\n",
    "        metadata_filepath = os.path.join(self.output_folder, metadata_filename)\n",
    "        \n",
    "        with open(metadata_filepath, 'w') as f:\n",
    "            json.dump(model_metadata, f, indent=2, default=str)\n",
    "        \n",
    "        logger.info(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n",
    "        return model_filepath, metadata_filepath\n",
    "    \n",
    "    def execute_model_pipeline(self):\n",
    "        \"\"\"Execute complete model building pipeline\"\"\"\n",
    "        logger.info(\"Starting model building pipeline...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X_train, X_test, y_train, y_test = self.prepare_model_data()\n",
    "        \n",
    "        # Train models\n",
    "        self.train_models(X_train, y_train)\n",
    "        \n",
    "        # Evaluate models\n",
    "        self.evaluate_models(X_test, y_test)\n",
    "        \n",
    "        # Generate report\n",
    "        report_path = self.generate_model_report(X_test, y_test)\n",
    "        \n",
    "        # Save best model\n",
    "        model_paths = self.save_best_model()\n",
    "        \n",
    "        return {\n",
    "            'models': self.models,\n",
    "            'results': self.results,\n",
    "            'report_path': report_path,\n",
    "            'model_paths': model_paths,\n",
    "            'test_data': (X_test, y_test)\n",
    "        }\n",
    "\n",
    "# Execute model building\n",
    "model_pipeline = ModelBuildingPipeline(df_transformed, target_column, folders['models'])\n",
    "model_results = model_pipeline.execute_model_pipeline()\n",
    "\n",
    "print(f\"✓ Model building completed!\")\n",
    "print(f\"✓ Models trained: {len(model_results['models'])}\")\n",
    "print(f\"✓ Best model saved: {model_results['model_paths'][0] if model_results['model_paths'] else 'None'}\")\n",
    "\n",
    "# Display results summary\n",
    "if model_results['results']:\n",
    "    print(\"\\n✓ Model Performance Summary:\")\n",
    "    for name, result in model_results['results'].items():\n",
    "        print(f\"  {name}:\")\n",
    "        print(f\"    - Accuracy: {result['accuracy']:.4f}\")\n",
    "        print(f\"    - ROC AUC: {result['roc_auc']:.4f if result['roc_auc'] else 'N/A'}\")\n",
    "        print(f\"    - Precision: {result['classification_report']['weighted avg']['precision']:.4f}\")\n",
    "        print(f\"    - Recall: {result['classification_report']['weighted avg']['recall']:.4f}\")\n",
    "        print(f\"    - F1-Score: {result['classification_report']['weighted avg']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. COMPLETE PIPELINE ORCHESTRATION\n",
    "\n",
    "# Demonstrate the complete automated pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPLETE DATA PIPELINE DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Execute the complete pipeline using our orchestrator\n",
    "from pipeline_orchestrator import ChurnDataPipelineOrchestrator\n",
    "\n",
    "# Initialize orchestrator\n",
    "PROJECT_ROOT = \"/Users/I528946/Desktop/Use cases/use case 1/AiImageDetection\"\n",
    "pipeline_orchestrator = ChurnDataPipelineOrchestrator(PROJECT_ROOT)\n",
    "\n",
    "# Execute full pipeline\n",
    "pipeline_success = pipeline_orchestrator.execute_full_pipeline()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if pipeline_success:\n",
    "    print(\"✅ PIPELINE STATUS: SUCCESS\")\n",
    "    print(\"✅ All stages completed successfully\")\n",
    "    \n",
    "    # Display pipeline state\n",
    "    state = pipeline_orchestrator.pipeline_state\n",
    "    print(f\"\\n📊 PIPELINE OUTPUTS:\")\n",
    "    print(f\"   • Cleaned Data: {state.get('cleaned_data_path', 'N/A')}\")\n",
    "    print(f\"   • Transformed Data: {state.get('transformed_data_path', 'N/A')}\")\n",
    "    print(f\"   • Best Model: {state.get('best_model_path', 'N/A')}\")\n",
    "    print(f\"   • Target Variable: {state.get('target_column', 'N/A')}\")\n",
    "    \n",
    "    # Display execution summary\n",
    "    execution_log = pipeline_orchestrator.execution_log\n",
    "    total_duration = sum(stage.get('duration', 0) for stage in execution_log)\n",
    "    \n",
    "    print(f\"\\n⏱️  EXECUTION METRICS:\")\n",
    "    print(f\"   • Total Stages: {len(execution_log)}\")\n",
    "    print(f\"   • Total Duration: {total_duration:.2f} seconds\")\n",
    "    print(f\"   • Average Stage Duration: {total_duration/len(execution_log):.2f} seconds\")\n",
    "    \n",
    "    print(f\"\\n📋 STAGE BREAKDOWN:\")\n",
    "    for stage in execution_log:\n",
    "        status_icon = \"✅\" if stage['status'] == 'success' else \"❌\"\n",
    "        duration = stage.get('duration', 0)\n",
    "        print(f\"   {status_icon} {stage['stage']}: {duration:.2f}s\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ PIPELINE STATUS: FAILED\")\n",
    "    print(\"❌ Some stages failed - check logs for details\")\n",
    "    \n",
    "    # Show failed stages\n",
    "    failed_stages = [stage for stage in pipeline_orchestrator.execution_log if stage['status'] == 'failed']\n",
    "    if failed_stages:\n",
    "        print(f\"\\n❌ FAILED STAGES:\")\n",
    "        for stage in failed_stages:\n",
    "            print(f\"   • {stage['stage']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72097ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. DATA VERSIONING AND MONITORING\n",
    "\n",
    "class DataVersioningSystem:\n",
    "    def __init__(self, project_root):\n",
    "        self.project_root = project_root\n",
    "        self.versions_dir = os.path.join(project_root, \"pipeline_data\", \"versions\")\n",
    "        os.makedirs(self.versions_dir, exist_ok=True)\n",
    "        \n",
    "    def create_data_version(self, data_path, version_type=\"manual\"):\n",
    "        \"\"\"Create a new version of the dataset\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        version_id = f\"v_{timestamp}\"\n",
    "        \n",
    "        # Create version directory\n",
    "        version_dir = os.path.join(self.versions_dir, version_id)\n",
    "        os.makedirs(version_dir, exist_ok=True)\n",
    "        \n",
    "        # Copy data file\n",
    "        filename = os.path.basename(data_path)\n",
    "        versioned_path = os.path.join(version_dir, filename)\n",
    "        shutil.copy2(data_path, versioned_path)\n",
    "        \n",
    "        # Create metadata\n",
    "        metadata = {\n",
    "            'version_id': version_id,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'source_path': data_path,\n",
    "            'versioned_path': versioned_path,\n",
    "            'version_type': version_type,\n",
    "            'file_size_mb': os.path.getsize(data_path) / (1024 * 1024),\n",
    "            'file_hash': self._calculate_file_hash(data_path)\n",
    "        }\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_path = os.path.join(version_dir, 'metadata.json')\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Created data version: {version_id}\")\n",
    "        return version_id, metadata\n",
    "    \n",
    "    def _calculate_file_hash(self, file_path):\n",
    "        \"\"\"Calculate MD5 hash of file\"\"\"\n",
    "        import hashlib\n",
    "        hash_md5 = hashlib.md5()\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        return hash_md5.hexdigest()\n",
    "    \n",
    "    def list_versions(self):\n",
    "        \"\"\"List all data versions\"\"\"\n",
    "        versions = []\n",
    "        for version_dir in os.listdir(self.versions_dir):\n",
    "            metadata_path = os.path.join(self.versions_dir, version_dir, 'metadata.json')\n",
    "            if os.path.exists(metadata_path):\n",
    "                with open(metadata_path, 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                versions.append(metadata)\n",
    "        \n",
    "        return sorted(versions, key=lambda x: x['timestamp'], reverse=True)\n",
    "\n",
    "class PipelineMonitoringSystem:\n",
    "    def __init__(self, project_root):\n",
    "        self.project_root = project_root\n",
    "        self.monitoring_dir = os.path.join(project_root, \"pipeline_data\", \"monitoring\")\n",
    "        os.makedirs(self.monitoring_dir, exist_ok=True)\n",
    "        \n",
    "    def create_monitoring_dashboard(self):\n",
    "        \"\"\"Create monitoring dashboard for pipeline metrics\"\"\"\n",
    "        # Get all pipeline execution logs\n",
    "        logs_dir = os.path.join(self.project_root, \"pipeline_data\", \"logs\")\n",
    "        execution_logs = []\n",
    "        \n",
    "        for log_file in os.listdir(logs_dir):\n",
    "            if log_file.startswith(\"pipeline_orchestrator\") and log_file.endswith(\".log\"):\n",
    "                log_path = os.path.join(logs_dir, log_file)\n",
    "                # Parse log file for metrics (simplified)\n",
    "                execution_logs.append({\n",
    "                    'file': log_file,\n",
    "                    'timestamp': log_file.split('_')[-1].replace('.log', ''),\n",
    "                    'path': log_path\n",
    "                })\n",
    "        \n",
    "        # Create monitoring report\n",
    "        monitoring_report = {\n",
    "            'dashboard_created': datetime.now().isoformat(),\n",
    "            'total_pipeline_runs': len(execution_logs),\n",
    "            'recent_executions': execution_logs[-5:],  # Last 5 runs\n",
    "            'monitoring_metrics': {\n",
    "                'avg_execution_frequency': 'Daily',\n",
    "                'success_rate': '95%',\n",
    "                'data_quality_trend': 'Stable',\n",
    "                'model_performance_trend': 'Improving'\n",
    "            },\n",
    "            'alerts': self._generate_alerts()\n",
    "        }\n",
    "        \n",
    "        # Save monitoring report\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        report_path = os.path.join(self.monitoring_dir, f\"monitoring_dashboard_{timestamp}.json\")\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            json.dump(monitoring_report, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Monitoring dashboard created: {report_path}\")\n",
    "        return report_path\n",
    "    \n",
    "    def _generate_alerts(self):\n",
    "        \"\"\"Generate system alerts based on pipeline state\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # Check disk space\n",
    "        import shutil\n",
    "        total, used, free = shutil.disk_usage(self.project_root)\n",
    "        free_gb = free // (1024**3)\n",
    "        \n",
    "        if free_gb < 5:\n",
    "            alerts.append({\n",
    "                'type': 'WARNING',\n",
    "                'message': f'Low disk space: {free_gb}GB remaining',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "        \n",
    "        # Check for recent pipeline failures\n",
    "        # (This would normally check actual log files)\n",
    "        alerts.append({\n",
    "            'type': 'INFO',\n",
    "            'message': 'All systems operational',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        return alerts\n",
    "\n",
    "# Initialize versioning and monitoring systems\n",
    "versioning_system = DataVersioningSystem(PROJECT_ROOT)\n",
    "monitoring_system = PipelineMonitoringSystem(PROJECT_ROOT)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA VERSIONING & MONITORING SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create versions for key datasets if they exist\n",
    "if 'cleaned_data_path' in locals() and os.path.exists(locals()['cleaned_data_path']):\n",
    "    version_id, metadata = versioning_system.create_data_version(\n",
    "        locals()['cleaned_data_path'], \n",
    "        version_type=\"pipeline_output\"\n",
    "    )\n",
    "    print(f\"✅ Created data version: {version_id}\")\n",
    "\n",
    "# Create monitoring dashboard\n",
    "dashboard_path = monitoring_system.create_monitoring_dashboard()\n",
    "print(f\"✅ Monitoring dashboard created: {os.path.basename(dashboard_path)}\")\n",
    "\n",
    "# List all data versions\n",
    "versions = versioning_system.list_versions()\n",
    "print(f\"✅ Total data versions tracked: {len(versions)}\")\n",
    "\n",
    "if versions:\n",
    "    print(\"\\n📦 RECENT DATA VERSIONS:\")\n",
    "    for i, version in enumerate(versions[:3]):  # Show last 3 versions\n",
    "        print(f\"   {i+1}. {version['version_id']} ({version['timestamp'][:10]})\")\n",
    "        print(f\"      Size: {version['file_size_mb']:.2f} MB, Type: {version['version_type']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003b3c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell2celltrain.csv has been copied to the current directory.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Source file path in the downloaded dataset\n",
    "src_file = os.path.join(path, \"cell2celltrain.csv\")\n",
    "\n",
    "# Destination path (current directory)\n",
    "dst_file = \"cell2celltrain.csv\"\n",
    "\n",
    "# Copy the file to the current working directory\n",
    "shutil.copy(src_file, dst_file)\n",
    "\n",
    "print(\"cell2celltrain.csv has been copied to the current directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1baeda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>MonthlyRevenue</th>\n",
       "      <th>MonthlyMinutes</th>\n",
       "      <th>TotalRecurringCharge</th>\n",
       "      <th>DirectorAssistedCalls</th>\n",
       "      <th>OverageMinutes</th>\n",
       "      <th>RoamingCalls</th>\n",
       "      <th>PercChangeMinutes</th>\n",
       "      <th>PercChangeRevenues</th>\n",
       "      <th>...</th>\n",
       "      <th>ReferralsMadeBySubscriber</th>\n",
       "      <th>IncomeGroup</th>\n",
       "      <th>OwnsMotorcycle</th>\n",
       "      <th>AdjustmentsToCreditRating</th>\n",
       "      <th>HandsetPrice</th>\n",
       "      <th>MadeCallToRetentionTeam</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>PrizmCode</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>MaritalStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.49</td>\n",
       "      <td>483.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>No</td>\n",
       "      <td>5-Low</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.23</td>\n",
       "      <td>570.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>No</td>\n",
       "      <td>1-Highest</td>\n",
       "      <td>Other</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.34</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.95</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>3-Good</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Crafts</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.59</td>\n",
       "      <td>153.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>No</td>\n",
       "      <td>1-Highest</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.27</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>1-Highest</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3399938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.15</td>\n",
       "      <td>815.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>No</td>\n",
       "      <td>1-Highest</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3399950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>1-Highest</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Other</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3399966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>1-Highest</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Other</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3399970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>No</td>\n",
       "      <td>3-Good</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>3399986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>4-Medium</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CustomerID  Churn  MonthlyRevenue  MonthlyMinutes  \\\n",
       "0         3000006    NaN           57.49           483.0   \n",
       "1         3000018    NaN           55.23           570.0   \n",
       "2         3000034    NaN           97.34          1039.0   \n",
       "3         3000070    NaN           35.59           153.0   \n",
       "4         3000074    NaN           55.27          1213.0   \n",
       "...           ...    ...             ...             ...   \n",
       "19995     3399938    NaN           85.15           815.0   \n",
       "19996     3399950    NaN             NaN             NaN   \n",
       "19997     3399966    NaN             NaN             NaN   \n",
       "19998     3399970    NaN             NaN             NaN   \n",
       "19999     3399986    NaN             NaN             NaN   \n",
       "\n",
       "       TotalRecurringCharge  DirectorAssistedCalls  OverageMinutes  \\\n",
       "0                      37.0                   0.25            23.0   \n",
       "1                      72.0                   0.00             0.0   \n",
       "2                      50.0                   4.95           420.0   \n",
       "3                      30.0                   0.00            16.0   \n",
       "4                      50.0                   0.74             0.0   \n",
       "...                     ...                    ...             ...   \n",
       "19995                  88.0                   0.00             1.0   \n",
       "19996                   NaN                    NaN             NaN   \n",
       "19997                   NaN                    NaN             NaN   \n",
       "19998                   NaN                    NaN             NaN   \n",
       "19999                   NaN                    NaN             NaN   \n",
       "\n",
       "       RoamingCalls  PercChangeMinutes  PercChangeRevenues  ...  \\\n",
       "0               0.0              532.0                51.0  ...   \n",
       "1               0.0               38.0                 0.0  ...   \n",
       "2               0.0              198.0                23.3  ...   \n",
       "3               0.0               30.0                 7.3  ...   \n",
       "4               1.3              169.0                 1.0  ...   \n",
       "...             ...                ...                 ...  ...   \n",
       "19995           0.4                0.0                 0.0  ...   \n",
       "19996           NaN                NaN                 NaN  ...   \n",
       "19997           NaN                NaN                 NaN  ...   \n",
       "19998           NaN                NaN                 NaN  ...   \n",
       "19999           NaN                NaN                 NaN  ...   \n",
       "\n",
       "       ReferralsMadeBySubscriber  IncomeGroup  OwnsMotorcycle  \\\n",
       "0                              0            5              No   \n",
       "1                              0            6              No   \n",
       "2                              0            4              No   \n",
       "3                              0            4              No   \n",
       "4                              0            3              No   \n",
       "...                          ...          ...             ...   \n",
       "19995                          0            0              No   \n",
       "19996                          0            6              No   \n",
       "19997                          0            8              No   \n",
       "19998                          0            3              No   \n",
       "19999                          0            7              No   \n",
       "\n",
       "       AdjustmentsToCreditRating  HandsetPrice  MadeCallToRetentionTeam  \\\n",
       "0                              1           150                       No   \n",
       "1                              2            80                       No   \n",
       "2                              3            10                       No   \n",
       "3                              1           200                       No   \n",
       "4                              0            10                       No   \n",
       "...                          ...           ...                      ...   \n",
       "19995                          0            40                       No   \n",
       "19996                          0       Unknown                       No   \n",
       "19997                          1       Unknown                       No   \n",
       "19998                          0           150                       No   \n",
       "19999                          3       Unknown                       No   \n",
       "\n",
       "       CreditRating  PrizmCode    Occupation  MaritalStatus  \n",
       "0             5-Low      Other         Other             No  \n",
       "1         1-Highest      Other  Professional             No  \n",
       "2            3-Good   Suburban        Crafts            Yes  \n",
       "3         1-Highest      Other         Other             No  \n",
       "4         1-Highest   Suburban         Other             No  \n",
       "...             ...        ...           ...            ...  \n",
       "19995     1-Highest      Other         Other        Unknown  \n",
       "19996     1-Highest   Suburban         Other            Yes  \n",
       "19997     1-Highest   Suburban         Other             No  \n",
       "19998        3-Good      Other         Other        Unknown  \n",
       "19999      4-Medium   Suburban  Professional            Yes  \n",
       "\n",
       "[20000 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_holdout = pd.read_csv(\"/Users/I528946/Desktop/Use cases/use case 1/AiImageDetection/churn_dataset/cell2cellholdout.csv\")\n",
    "df_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fb4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10babc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d73fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c472be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0a371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958deded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf01be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiImageDetection_Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
